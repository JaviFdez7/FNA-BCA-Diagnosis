---
title: "R Notebook"
output:
  html_notebook: default
  word_document: default
  pdf_document: default
  html_document:
    df_print: paged
---

---
title: "R Notebook"
output: html_notebook
---

 <font size="5"> Conjunto de datos de di치gnostico de c치ncer de mama en Wisconsin. </font> 
 
<font size="4"> 1. An치lisis Inicial y Preprocesamiento de los Datos. </font> 


<fotn size="3">1.1 Importaci칩n y Carga de Datos. </font> 

Para comenzar nuestro an치lisis es necesario realizar la carga de los datos:


```{r}

data <- read.csv("data/data.csv")

data

```

Instalamos los paquetes que ser치n necesarios durante nuestro proyecto:

+ Tidyverse: Para la manipulaci칩n de datos y gr치ficos.
+ Caret: Para el preprocesamiento y modelado
  Lattice es requerido por Caret
+ DataExplorer: Para la exploraci칩n automatizada de los datos.
+ Dplyr: Proporciona una gram치tica de manipulaci칩n de datos.
+ Ggplot2: Personalizaci칩n de gr치ficas.
+ Psych: Para an치lisis estad칤stico
+ Corrplot: Visualizaci칩n de matriz de correlaci칩n.

```{r}

#install.packages("tidyverse")
#install.packages("caret")
#install.packages("DataExplorer")
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("lattice")
#install.packages("psych")
#install.packages("corrplot")
#install.packages("ggcorrplot")

library(caret)
library(DataExplorer)
library()
library(dplyr)
library(ggplot2)
library(tidyverse)
library(lattice)
library(psych)
library(corrplot)
library(ggcorrplot)




```


Hagamos una vista inicial de los datos:
```{r}
#primeras filas de nuestro dataset:

head(data)
```
```{r}
# Dimensi칩n de nuestro dataset:

dim(data)
```
Nuestro dataset cuenta con 33 columnas y 569 filas.

```{r}
# Con str mostramos la estructura de nuestro dataframe, incluyendo los tipos de nuestras variables:

str(data)
```
```{r}

# Con Describe podemos ver un primer resumen estad칤stico b치sico:

describe(data)

```

```{r}
# Tipos de datos en nuestras variables:

sapply(data, class)
```
```{r}
# Veamos si existen valores faltantes en nuestros datos:

anyNA(data)
```
```{r}
#Contamos el numero de valores faltantes por columna:

colSums(is.na(data))
plot_missing(data)
```
Como puede observarse, contamos con 569 valores faltantes en la 칰ltima columna "X". M치s adelante veremos como tratarlo.


<font size="3">1.2 An치lisis exploratorio de los datos </font> 

En este paso nuestro objetivo ser치 entender la distribuci칩n y relaciones de variables.

<font size="2">Visualizaci칩n de distribuciones y correlaciones: </font> 

```{r}
#Veamos un resumen gr치fico general:

plot_intro(data)
```

```{r}
#Variables Categ칩ricas:

plot_bar(data)
```
```{r}
#Variables Num칠ricas
plot_histogram(data)
```


<font size="3">1.3 Preprocesamiento de los datos. </font> 

<font size="2">Eliminaci칩n de valores faltantes: </font> 



Para comenzar, ya sabemos que existe una columna cuyos valores son todos NA, es decir, faltantes. El primero paso en nuestro preprocesamiento ser치 eliminar esta columna "x":

```{r}
data <- read.csv("data/data.csv")
data
head(data)
```

```{r}
data <- data %>% select(-X)
```

Veamos si se ha borrado correctamente la columna X y si ahora existe alg칰n otro valor faltante:

```{r}
colnames(data)
```
```{r}
# Veamos si existen valores faltantes en nuestros datos:

anyNA(data)

#Contamos el numero de valores faltantes por columna:

colSums(is.na(data))
plot_missing(data)
```

Adem치s de la columna con valores Faltantes, tambi칠n tenemos una columna "ID" que no nos aporta ninguna informaci칩n por lo que tambi칠n procederemos a eliminarla:

```{r}
data <- data %>% select(-id)

```


```{r}
colnames(data)
head(data)

```

Como podemos observar, se ha eliminado la columna "id" y se ha verificado que no existen mas valores faltantes exceptos los ya eliminados en "X".

Despu칠s de ellos contamos con un dataset de:

```{r}
dim(data)
```
569 filas y 31 columnas.

<font size="2"> Codificaci칩n de variables Categ칩ricas </font> 


Anteriormente vimos que nuestro dataset cuenta con una 칰nica columna de valores categ칩ricos. "Diagnosis" cuyos valores tienen el siguiente significado:
+ M (malignant)
+ B (benign)

El siguiente paso en el preprocesado de datos ser치 pasar esta columna a num칠rica. Como solo se presentan dos posibles valores (M y B), se aplicar치 Codificaci칩n Binaria: El valor "M" pasar치 a ser 1 y valor "B" pasar치 a ser 0.

Aunque m치s adelante volveremos a pasarla a categ칩rica, ahora es necesario hacerla binaria para poder estudiar la correlaci칩n de las variables.

```{r}

#M -> 1; B -> 0
data$diagnosis <- ifelse(data$diagnosis == "M", 1, 0)
```

Vamos a verificar que se ha realizado correctamente la conversi칩n:

```{r}
table(data$diagnosis)
print(data$diagnosis)
```
Nos cercioramos de que no existe ning칰n otro valor categ칩rico en el dataset:
```{r}

categorical_columns <- sapply(data, is.factor) | sapply(data, is.character)
names(data)[categorical_columns]


```
Efectivamente, todas nuestras columnas ahora son num칠ricas, lo que nos da paso al siguiente punto en nuestro preprocesamiento de datos.

<font size="2"> Estudio de correlaci칩n. </font> 


Al tener nuestro dataset limpio de NA y solo presentes variables num칠ricas,  el siguiente paso ser치 estudiar las posibles correlaciones de nuestro dataset.

Estudiar la correlaci칩n de los datos ayuda a identificar patrones y relaciones entre variables, lo que podr칤a conducir a nuevas hip칩tesis y descubrimientos. Adem치s, un buen estudio de correlaciones podr칤a ser 칰til para seleccionar variables relevantes y construir modelos en un futuro.


Los valores que obtendremos tendr치n la siguiente interpretaci칩n:

+ Correlaci칩n cercana a 1: Relaci칩n positiva fuerte.
+ Correlaci칩n cercana a -1: Relaci칩n negativa fuerte.
+ Correlaci칩n cercana a 0: No hay relaci칩n lineal significativa

```{r}

# Calcular matriz de correlaci칩n
correlation_matrix <- cor(data, use = "complete.obs")  # Ignora valores faltantes


# Graficar matriz de correlaci칩n
corrplot(correlation_matrix, method = "color", type = "upper", tl.cex = 0.8)

```
```{r}

# Graficar la matriz de correlaci칩n con valores en las celdas
ggcorrplot(correlation_matrix, 
           method = "circle",  # Utilizar c칤rculos para representar correlaciones
           type = "lower",     # Mostrar solo la mitad inferior
           lab = TRUE,         # A침adir los valores de correlaci칩n
           lab_size = 2,       # Tama침o del texto en las celdas
           colors = c("blue", "white", "red"), # Colores para las correlaciones negativas, neutrales y positivas
           title = "Matriz de Correlaci칩n",  # T칤tulo del gr치fico
           tl.cex = 10)       # Tama침o de las etiquetas

```
Como puede observarse, al tratarese un conjunto de datos con 31 variables, la matriz de correlaci칩n cuesta interpretarla.

Por ello, como "diagnosis" es nuestra variable objetivo, vamos a observar c칩mo se correlacionan las dem치s variables con ella:


```{r}
# Calcular la correlaci칩n entre cada variable num칠rica y 'diagnosis'
cor_with_target <- cor(data, data$diagnosis, use = "complete.obs")

# Crear un data frame para ver las correlaciones junto con los nombres de las variables
correlation_df <- data.frame(Variable = names(data), Correlation = cor_with_target)

# Ordenar el data frame por la columna de Correlation en orden descendente
correlation_df_sorted <- correlation_df[order(-correlation_df$Correlation), ]

# Ver las correlaciones ordenadas junto con los nombres de las variables
print(correlation_df_sorted)


```
En esta tabla podemos ver la correlaci칩n de cada variable con "diagnosis" en orden descendente.


<font size="2">Selecci칩n de Atributos: </font> 

Una de las formas de hacer una correcta selecci칩n de atributos es inspeccionar la anterior tabla de correlaci칩n:

Como puede observarse, no existe ninguna variable que supere el 0,8, cuando las variables se correlacionan con la variable clase, en nuestro caso diagnosis, con m치s de un 0,9, suele ser conveniente eliminarlas para evitar redundancia, lo que no es nuestro caso. 

Por otro lado, tampoco tenemos valores demasiado bajos ni negativos, los valores negativos en nuestro caso, podr칤an ayudar al entrenamiento de nuestro modelo, es por ello, que de momento no se eliminar치n variables del dataset. 

<font size="4"> 2. An치lisis Supervisado.</font> 

El aprendizaje supervisado, tambi칠n conocido como machine learning supervisado, es una subcategor칤a del machine learning y la inteligencia artificial. Se define por el uso de conjuntos de datos etiquetados para entrenar algoritmos que clasifican los datos o predicen los resultados con precisi칩n.

A medida que se introducen datos en el modelo, 칠ste ajusta sus ponderaciones hasta que el modelo se ha ajustado adecuadamente, lo que ocurre como parte del proceso de validaci칩n cruzada. 

En nuestro an치lisis, la variable a predecir ser치 "diagnosis", que como vimos anteriormente, es de tipo binario, tomando 1 cuando el tumor es maligno, y 0 cuando el tumor resulta benigno.

En este an치lisis se han evaluado diferentes modelos de clasificaci칩n para un conjunto de datos binario con 569 muestras y 30 predictores, clasificados en dos categor칤as: 'Negative' y 'Positive'. Los modelos analizados son el 츼rbol de Decisi칩n (CART), Random Forest (Bosque Aleatorio), M치quinas de Soporte Vectorial con n칰cleo Radial (SVM), y el Modelo Lineal Generalizado (GLM).

El primer paso para el an치lisis supervisado es realizar la divi칩n del dataset.

<font size="2">2.1 Divisi칩n del Dataset: </font> 




Para este paso, usaremos la validaci칩n cruzada k-fold para dividir el dataset y evaluar el modelo. Aunque podr칤amos dividir el conjunto en un 80% train y un 20% train, valores t칤picos, se ha optado por utilizar K-fold ya que asegura que cada subconjunto o fold del dataset es utilizado tanto para el entrenamiento como para prueba en distintas iteraciones, lo que nos proporcionar치 una evaluaci칩n m치s robusta.

```{r}
#Cargamos la librer칤a caret
library(caret)

#Configuramos la validaci칩n cruzada K-fold
set.seed(123)

k <- 5 

# Configurar K-fold Cross-Validation con probabilidades de clase
train_control <- trainControl(
  method = "cv",           # Cross-validation
  number = k,              # N칰mero de pliegues (folds)
  classProbs = TRUE,       # Habilitar probabilidades de clase
  summaryFunction = twoClassSummary, # Para m칠tricas de clasificaci칩n binaria
  savePredictions = "final" # Guardar las predicciones finales
)


```



<font size="2">2.2 Entrenamiento del modelo: </font> 

  
  Cambiamos los niveles del factor "diagnosis" a nombres v치lidos, en este caso "positivo", "negativo".
```{r}
# Entrenar el modelo de Random Forest utilizando K-fold cross-validation
set.seed(123)

#Vamos a convertir
data$diagnosis <- factor(data$diagnosis, levels = c(0, 1), labels = c("Negative", "Positive"))
```


  <font size="2">2.2.1 츼rbol de Decisi칩n (CART): </font> 
  
  El 치rbol de decisi칩n es un modelo simple que divide los datos en segmentos basados en reglas de decisi칩n. Es 칰til para clasificaciones donde las decisiones son l칩gicas y f치ciles de entender
  
```{r}

# 츼rbol de Decisi칩n utilizando K-fold cross-validation
model_cart <- train(
  diagnosis ~ .,        # Usamos todas las variables predictoras
  data = data,
  method = "rpart",     # 츼rbol de decisi칩n (CART)
  trControl = train_control,  # Control de validaci칩n cruzada
  metric = "ROC"        # Evaluar utilizando AUC (츼rea bajo la curva ROC)
)

# Ver el resumen del modelo entrenado
print(model_cart)

# Extraer la importancia de las variables
importance_cart <- varImp(model_cart, scale = FALSE)
importance_cart_df <- importance_cart$importance
importance_cart_df$variable <- rownames(importance_cart_df)

```
El primer modelo analizado es el 츼rbol de Decisi칩n (CART). Este modelo utiliza un valor de complejidad de poda (cp) de 0.0047, que fue seleccionado como el mejor par치metro mediante validaci칩n cruzada.

La curva ROC del modelo es de 0.9362, lo que indica una alta capacidad para discriminar entre las dos clases. 

La sensibilidad (capacidad del modelo para identificar correctamente las observaciones positivas) es de 0.9383, lo que sugiere que el modelo es muy eficiente para detectar las observaciones positivas, aunque algo menos efectivo que otros modelos en cuanto a la especificidad. De hecho, la especificidad (capacidad para identificar correctamente las observaciones negativas) es de 0.8960, lo que representa una leve ca칤da respecto a la sensibilidad. 

Este desempe침o es s칩lido y equilibrado, pero no es el m치s alto entre los modelos evaluados.

    <font size="2">2.2.2 Random Forest </font> 

El Random Forest es un algoritmo que construye m칰ltiples 치rboles de decisi칩n y realiza una predicci칩n agregando las predicciones de todos los 치rboles individuales. Es robusto ante el sobreajuste.
```{r}
model_rf <- train(
  diagnosis ~ .,        # Usamos todas las variables predictoras
  data = data,
  method = "rf",        # Random Forest
  trControl = train_control,  # Control de validaci칩n cruzada
  metric = "ROC"        # Evaluar utilizando AUC (츼rea bajo la curva ROC)
)

# Ver el resumen del modelo entrenado
print(model_rf)

# Extraer la importancia de las variables
importance_rf <- varImp(model_rf, scale = FALSE)
importance_rf_df <- importance_rf$importance
importance_rf_df$variable <- rownames(importance_rf_df)

```
  
Para entender mejor los resultados del modelo, aclarar que el par치metro mtry en el contexto de Random Forest es uno de los hiperpar치metros clave que se utiliza para controlar el n칰mero de variables (caracter칤sticas) que el modelo considera para dividir cada nodo en cada 치rbol del bosque. Espec칤ficamente, mtry define cu치ntas caracter칤sticas ser치n elegidas aleatoriamente para cada nodo cuando se construye un 치rbol en el Random Forest.
 
 
Random Forest, muestra un desempe침o destacable. Este modelo seleccion칩 el valor de mtry (n칰mero de variables aleatorias para cada divisi칩n del 치rbol) igual a 2, lo que optimiza la capacidad de discriminaci칩n. Su curva ROC alcanza un valor impresionante de 0.9908, lo que es un indicador claro de su capacidad para separar las dos clases con gran precisi칩n. Adem치s, la sensibilidad de 0.9804 muestra que Random Forest tiene una excelente capacidad para detectar correctamente las observaciones positivas, y la especificidad de 0.9241 indica que tambi칠n es eficaz en identificar las observaciones negativas. Este modelo sobresale por su alta precisi칩n en ambos aspectos, lo que lo convierte en uno de los modelos m치s robustos y confiables para este conjunto de datos.

  <font size="2">2.2.3 Support Vector Machine (SVM) </font> 
  
  El Support Vector Machine (SVM) es un algoritmo que intenta encontrar un hiperplano que mejor separe las diferentes clases de datos.
  

```{r}
#install.packages("kernlab")
library(kernlab)

model_svm <- train(
  diagnosis ~ .,        # Usamos todas las variables predictoras
  data = data,
  method = "svmRadial",  # Support Vector Machine con kernel radial
  trControl = train_control,  # Control de validaci칩n cruzada
  metric = "ROC"        # Evaluar utilizando AUC (츼rea bajo la curva ROC)
)

# Ver el resumen del modelo entrenado
print(model_svm)

# Extraer la importancia de las variables
importance_svm <- varImp(model_svm, scale = FALSE)
importance_svm_df <- importance_svm$importance
importance_svm_df$variable <- rownames(importance_svm_df)

```
El tercer modelo evaluado es el de M치quinas de Soporte Vectorial con n칰cleo Radial (SVM). Este modelo, con un par치metro de regularizaci칩n 洧냤=1 y un valor de sigma de 0.0475, mostr칩 un desempe침o excelente en t칠rminos de la curva ROC, alcanzando un valor de 0.9948, el m치s alto entre todos los modelos. Esta m칠trica refleja una capacidad de discriminaci칩n superior, lo que implica que el modelo tiene una alta habilidad para separar correctamente las clases 'Negative' y 'Positive'. La sensibilidad de 0.9748 y la especificidad de 0.9670 tambi칠n son notablemente altas, lo que sugiere que el modelo tiene un buen rendimiento tanto en la detecci칩n de las observaciones positivas como en la correcta identificaci칩n de las negativas. Sin embargo, es importante destacar que el modelo SVM present칩 varias advertencias durante el proceso de optimizaci칩n (warnings), relacionadas con problemas de convergencia y probabilidades extremas de 0 o 1. Esto podr칤a indicar que el modelo podr칤a estar sobreajustando o enfrentando dificultades para encontrar un equilibrio estable, lo que debe tenerse en cuenta al evaluar su estabilidad y generalizaci칩n.


  <font size="2">2.2.4 Regresi칩n Log칤stica </font> 
  
  Este algoritmo es un modelo de clasificaci칩n que predice la probabilidad de que una observaci칩n pertenzca a una clase o no.
  
```{r}


model_logit <- train(
  diagnosis ~ .,        # Usamos todas las variables predictoras
  data = data,
  method = "glm",       # Regresi칩n Log칤stica
  trControl = train_control,  # Control de validaci칩n cruzada
  metric = "ROC"        # Evaluar utilizando AUC (츼rea bajo la curva ROC)
)

# Ver el resumen del modelo entrenado
print(model_logit)

# Extraer la importancia de las variables
importance_logit <- varImp(model_logit, scale = FALSE)
importance_logit_df <- importance_logit$importance
importance_logit_df$variable <- rownames(importance_logit_df)

```
El 칰ltimo modelo considerado es el Modelo Lineal Generalizado (GLM). Este modelo, a pesar de ser sencillo en su estructura, mostr칩 un rendimiento respetable. Su curva ROC alcanz칩 un valor de 0.9552, lo cual es inferior a los de Random Forest y SVM, pero sigue siendo adecuado para tareas de clasificaci칩n. La sensibilidad de 0.9438 indica que el modelo tiene una buena capacidad para identificar las observaciones positivas, mientras que la especificidad de 0.9484 es ligeramente mejor que la sensibilidad, lo que sugiere que el modelo tiene un desempe침o ligeramente mejor para detectar las observaciones negativas en comparaci칩n con las positivas. Aunque el modelo GLM es funcional, su rendimiento en t칠rminos de la curva ROC es algo inferior en comparaci칩n con los modelos m치s complejos como SVM y Random Forest.  

  <font size="2">2.3 Comparaci칩n de Modelos </font> 

```{r}
# Comparar el rendimiento de los modelos
resamples <- resamples(list(cart = model_cart, rf = model_rf, svm = model_svm, logit = model_logit))

# Ver el resumen de la comparaci칩n entre los modelos
summary(resamples)

# Visualizaci칩n de la comparaci칩n
bwplot(resamples)

```

  <font size="2">2.4 Estudio de la Importancia de las Variables </font> 



